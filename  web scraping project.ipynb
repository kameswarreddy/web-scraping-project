{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41a2d3ff",
   "metadata": {},
   "source": [
    "# python project\n",
    "\n",
    "# Scraping Top Repositories for Topics on GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2cac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project outline\n",
    "#--------> use requests to downlaod the page\n",
    "#--------> user BS4 to parse and extract information\n",
    "#--------> convert to a Pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f178e7b",
   "metadata": {},
   "source": [
    "# Importing required libraries\n",
    "#-> collecting name of topic,description and urls from github website details \n",
    "#-> collecting data is stored in the form of csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "57c1b32c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\bharath kuamr reddy\\ykr\\lib\\site-packages (2.26.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bharath kuamr reddy\\ykr\\lib\\site-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\bharath kuamr reddy\\ykr\\lib\\site-packages (from requests) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\bharath kuamr reddy\\ykr\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bharath kuamr reddy\\ykr\\lib\\site-packages (from requests) (3.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\bharath kuamr reddy\\ykr\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\bharath kuamr reddy\\ykr\\lib\\site-packages (from beautifulsoup4) (2.2.1)\n"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    "!pip install requests\n",
    "!pip install beautifulsoup4\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717e5fc9",
   "metadata": {},
   "source": [
    "#  getting topic page and its url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "b2333734",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/topics'\n",
    "def get_Github_topicnames(url):\n",
    "    \n",
    "    ## importing required libraries\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    response.status_code\n",
    "    len(response.text)\n",
    "    \n",
    "    ## storing web page content in variable to tranfer into a new html file\n",
    "    \n",
    "    content = response.text\n",
    "    with open('webpage.html', 'w',encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "        \n",
    "    ## beautifulsoup package is used to parse the web page content\n",
    "    \n",
    "    doc = BeautifulSoup(content, 'html.parser')\n",
    "    \n",
    "    ## storing all p-tags and class related to topic name, decription and web-URL\n",
    "    \n",
    "    topicp_tag = doc.find_all('p',{'class': \"f3 lh-condensed mb-0 mt-1 Link--primary\"})\n",
    "    dcrp_tag = doc.find_all('p',{'class':\"f5 color-fg-muted mb-0 mt-1\"})\n",
    "    topic_links = doc.find_all('a',{'class':\"no-underline flex-1 d-flex flex-column\"})\n",
    "    \n",
    "    ## initialise the empty list to store required  details\n",
    "    \n",
    "    tpc_name = []\n",
    "    decr = []\n",
    "    pagelinks  = []\n",
    "    for i in topicp_tag:\n",
    "        tpc_name.append(i.text)\n",
    "    \n",
    "    for i in dcrp_tag:\n",
    "        decr.append(i.text.strip())\n",
    "    \n",
    "    for i in topic_links:\n",
    "        pagelinks.append('https://github.com/'+i['href'])\n",
    "        \n",
    "    ## creating a DataFrame of required details using pandas\n",
    "\n",
    "    dictn = {'Topic':tpc_name,'Topic Description':decr,'Topic URL': pagelinks}\n",
    "    dataframe = pd.DataFrame(dictn)\n",
    "    topic_links = pagelinks\n",
    "    return dataframe,topic_links,tpc_name,pagelinks\n",
    "\n",
    "## saving  the data in CSV format\n",
    "\n",
    "df.to_csv('github webscape.csv')\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a20e191",
   "metadata": {},
   "source": [
    "# collecting from out of topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "c84c68a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete-------->3D\n",
      "complete-------->Ajax\n",
      "complete-------->Algorithm\n",
      "complete-------->Amp\n",
      "complete-------->Android\n",
      "complete-------->Angular\n",
      "complete-------->Ansible\n",
      "complete-------->API\n",
      "complete-------->Arduino\n",
      "complete-------->ASP.NET\n",
      "complete-------->Atom\n",
      "complete-------->Awesome Lists\n",
      "complete-------->Amazon Web Services\n",
      "complete-------->Azure\n",
      "complete-------->Babel\n",
      "complete-------->Bash\n",
      "complete-------->Bitcoin\n",
      "complete-------->Bootstrap\n",
      "complete-------->Bot\n",
      "complete-------->C\n",
      "complete-------->Chrome\n",
      "complete-------->Chrome extension\n",
      "complete-------->Command line interface\n",
      "complete-------->Clojure\n",
      "complete-------->Code quality\n",
      "complete-------->Code review\n",
      "complete-------->Compiler\n",
      "complete-------->Continuous integration\n",
      "complete-------->COVID-19\n",
      "complete-------->C++\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "for j in range(len(pagelinks)):\n",
    "    topic_url = pagelinks[j]\n",
    "    res = requests.get(topic_url)\n",
    "    if res.status_code!=200:\n",
    "        print('occur error')\n",
    "    cnt = res.text\n",
    "    #len(cnt)\n",
    "    topic_doc = BeautifulSoup(cnt,'html.parser')\n",
    "    topic_name = topic_doc.find_all('h3',{'class':\"f3 color-fg-muted text-normal lh-condensed\"})\n",
    "    stars = topic_doc.find_all('span',{'class':\"Counter js-social-count\"})\n",
    "    user=[]\n",
    "    repo=[]\n",
    "    user_link = []\n",
    "    stars_got = []\n",
    "    for i in range(len(topic_name)):\n",
    "        atags=topic_name[i].find_all('a')\n",
    "        username = atags[0].text.strip()\n",
    "        userrepo = atags[1].text.strip()\n",
    "        \n",
    "        ### constructing url for username and therir repos urls\n",
    "        \n",
    "        user_url = 'https://github.com'+atags[0]['href']\n",
    "        user.append(username)\n",
    "        repo.append(userrepo)\n",
    "        user_link.append(user_url)\n",
    "        stars_got.append(stars[i].text)\n",
    "        \n",
    "        #print(stars[i].text)\n",
    "\n",
    "    dit = {'users':user,'repos':repo,'user_links':user_link,'Stars':stars_got}\n",
    "    top_detail = pd.DataFrame(dit)\n",
    "    top_detail.to_csv(str(j)+'.'+'csv')\n",
    "    print('complete'+'-------->'+tpc_name[j])\n",
    "#### All individual csv file are stored in a C-drive on my laptop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5836d85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619e11b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
